# -*- coding: utf-8 -*-
"""main

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sRD5jL5SKOqjVD0m4alB2M39RkHaATxj
"""

import os
import warnings

warnings.filterwarnings("ignore")
np.random.seed(0)

def liste_dir_func(vehicle,num):
    up=0
    down=0
    right=0
    left=0
    liste_dir=[]
    for i in range(num):
        if vehicle[i].direction=='d':
            down=down+1
        elif  vehicle[i].direction=='u':
            up=up+1
        elif vehicle[i].direction=='l':
            left=left+1
        else:
            right=right+1
    liste_dir.append(down)
    liste_dir.append(up)
    liste_dir.append(left)
    liste_dir.append(right)
    return liste_dir
    
def liste_dir_task_func(vehicle,num):
    up=0
    down=0
    right=0
    left=0
    liste_dir=[]
    for i in range(num):
        if vehicle[i].direction=='d':
            down=down+1
        elif  vehicle[i].direction=='u':
            up=up+1
        elif vehicle[i].direction=='l':
            left=left+1
        else:
            right=right+1
    liste_dir.append(down)
    liste_dir.append(up)
    liste_dir.append(left)
    liste_dir.append(right)
    return liste_dir

def concatenat(liste):
  l=[]
  for p in range(len(liste)):
      m=[]
      if len(liste[0][0][0])<=3:
        m=liste[p][0][0]
        m.append(liste[p][0][1])
        m.append(liste[p][0][2])
        m.append(liste[p][0][3])
        l.append(np.array(m))
      else: 
        l.append(np.array(liste[p][0][0]))
  return l

# configuration


config = dict(
  learning_rate_actor = ACTOR_LR,
  learning_rate_critic = CRITIC_LR,
  batch_size = BATCH_SIZE,
  architecture = "MADDPG",
  infra = "Colab",
  env = ENV_NAME
)

wandb.init(
  project=f"tensorflow2_madddpg_good_one{ENV_NAME.lower()}",
  tags=["MADDPG", "RL"],
  config=config,
)

print('Simulation pour l\'entrainement des agents')
print('\n')
print('###############################################################################################')
print('\n')
print('Initilisation des environnements des Similations')
print('\n')
n_task = 24
n_serv= 28
print('Nous avons',n_task,'véhicules de tâches et ',n_serv,'véhcules de services dans notre environnement de simulations \n')
print('###############################################################################################')
print('\n')
up_lanes = [i/2.0 for i in [3.5/2,3.5/2 + 3.5,250+3.5/2, 250+3.5+3.5/2, 500+3.5/2, 500+3.5+3.5/2]]
down_lanes = [i/2.0 for i in [250-3.5-3.5/2,250-3.5/2,500-3.5-3.5/2,500-3.5/2,750-3.5-3.5/2,750-3.5/2]]
left_lanes = [i/2.0 for i in [3.5/2,3.5/2 + 3.5,433+3.5/2, 433+3.5+3.5/2, 866+3.5/2, 866+3.5+3.5/2]]
right_lanes = [i/2.0 for i in [433-3.5-3.5/2,433-3.5/2,866-3.5-3.5/2,866-3.5/2,1299-3.5-3.5/2,1299-3.5/2]]
width = 750/2
height = 1298/2
n_task = 24
n_neighbor = 28
n_RB = n_task
     
up_lanes = [i/2.0 for i in [3.5/2,3.5/2 + 3.5,250+3.5/2, 250+3.5+3.5/2, 500+3.5/2, 500+3.5+3.5/2]]
down_lanes = [i/2.0 for i in [250-3.5-3.5/2,250-3.5/2,500-3.5-3.5/2,500-3.5/2,750-3.5-3.5/2,750-3.5/2]]
left_lanes = [i/2.0 for i in [3.5/2,3.5/2 + 3.5,433+3.5/2, 433+3.5+3.5/2, 866+3.5/2, 866+3.5+3.5/2]]
right_lanes = [i/2.0 for i in [433-3.5-3.5/2,433-3.5/2,866-3.5-3.5/2,866-3.5/2,1299-3.5-3.5/2,1299-3.5/2]]

width = 750/2
height = 1298/2
n_serv = 28
n_neighbor = 24
n_RB = n_serv

MAX_EPISODES = 20
MAX_EP_STEPS = 50

rsu=RSU(4)
RSU=rsu.add_rsu()

################################################################################################################################
cloud=CloudServer()
env_serv = Environnement_service(down_lanes, up_lanes, left_lanes, right_lanes, width, height, n_serv, n_neighbor,CloudServer())
env_serv.new_random_game()

env_task = Environnement_task(down_lanes, up_lanes, left_lanes, right_lanes, width, height, n_task, n_neighbor)
env_task.new_random_game()

task=Task()

vehicle_serv=env_serv.vehicles
vehicle_task=env_task.vehicles



liste_dir=liste_dir_func(vehicle_serv,n_serv)
liste_dir_task=liste_dir_task_func(vehicle_task,n_task)




liste=task.global_task(n_task)
liste_t=task.max_time_add_to_task(vehicle_task,liste)
liste_tu=task.task_to_subtask(liste_t,vehicle_serv,liste_dir)

ressource=vehicle_task[0].list_resource_required(liste_tu,vehicle_task,vehicle_serv,liste_dir)
price_base=vehicle_serv[0].action_space(vehicle_serv)
ressource_ve_task=vehicle_task[0].liste_ressouce(vehicle_task)
resource_serv=vehicle_serv[0].resource(vehicle_serv)



price_task_u=vehicle_serv[0].price_task_u(price_base,liste_tu,ressource,resource_serv,liste_dir,liste_dir_task)

V2v=V2Vchannel()
data_rate_liste_v=V2v.liste_data_rate_v2v(vehicle_serv,vehicle_task)
V2i=V2Ichannel()
data_rate_liste_i=V2i.liste_data_rate_v2i(vehicle_serv,RSU)
ressource_service_util=vehicle_serv[0].ressource_utilization(ressource,liste_dir,liste_dir_task)


print('Initilisation des mémoires des Agents')
BUFFER_CAPACITY = 10000
BATCH_SIZE = 1000

task_memory=ReplayBuffer_Task(BUFFER_CAPACITY,BATCH_SIZE,vehicle_task,liste_dir_task,liste_dir,env_task,data_rate_liste_v,data_rate_liste_i,liste_tu,price_task_u,ressource)

import numpy as np
import tensorflow as tf
import time
import json
import os
import sys
from tqdm import tqdm
#import wandb
sys.path.append("../src")

#Main file
score_servs = []
score_tasks=[]
start_time = time.time()
n_serv = 28
n_task=24

for i in range (1):
  

  cloud=CloudServer()
  ressource_cloud=cloud.ressource
  env_serv = Environnement_service(down_lanes, up_lanes, left_lanes, right_lanes, width, height, n_serv, n_neighbor,cloud)
  env_serv.new_random_game()


  V2v=V2Vchannel()
  V2i=V2Ichannel()

  env_task = Environnement_task(down_lanes, up_lanes, left_lanes, right_lanes, width, height, n_task, n_neighbor)
  env_task.new_random_game()
  
  


  ############### pour chaque étape
  """ env_task.renew_positions()
    env_serv.renew_positions()
    env_task.renew_neighbor()
    env_serv.renew_neighbor()"""

  
  vehicle_serv=env_serv.vehicles
  vehicle_task=env_task.vehicles
  liste_dir=liste_dir_func(vehicle_serv,n_serv)
  liste_dir_task=liste_dir_task_func(vehicle_task,n_task)

  ressource_ve_task=vehicle_task[0].liste_ressouce_l(liste_dir_task)
  resource_serv=vehicle_serv[0].ressource_l(liste_dir)
  print(i)
  for bb in range(15):
   
          print(bb)
          #vehicle_serv=env_serv.vehicles
          #vehicle_task=env_task.vehicles
          
          liste_dir=liste_dir_func(vehicle_serv,n_serv)
          liste_dir_task=liste_dir_task_func(vehicle_task,n_task)
          
          print(liste_dir)
          print(liste_dir_task)
          task=Task()
          #liste=task.global_task_l(n_task)
          liste_tt=task.global_task_l(liste_dir_task)
          #print(liste_tt)
          liste_tt=task.max_time_add_to_task_l(vehicle_task,liste_tt)
          liste_tu=task.task_to_subtask_l(liste_tt,liste_dir,liste_dir_task)

          data_rate_liste_v=V2v.liste_data_rate_v2v(vehicle_serv,vehicle_task)
          data_rate_liste_i=V2i.liste_data_rate_v2i(vehicle_task,RSU)
          

          # ne pas oublier la mise a jour des ressources 
          price_base=vehicle_serv[0].action_space_l(liste_dir)
          ressource=vehicle_task[0].list_resource_required(liste_tu,vehicle_task,vehicle_serv,liste_dir)
          ressource_serv=vehicle_serv[0].liste_update_resource(ressource,resource_serv,liste_dir,liste_dir_task)
          price_task_u=vehicle_serv[0].price_task_u(price_base,liste_tu,ressource,resource_serv,liste_dir,liste_dir_task)
          ressource_service_util=vehicle_serv[0].ressource_utilization(ressource,liste_dir,liste_dir_task)

          state_serv=vehicle_serv[0].state_space(vehicle_serv,env_serv,resource_serv,ressource,liste_dir,liste_dir_task)
          state_task=vehicle_task[0].state_space(vehicle_task,env_task,data_rate_liste_v,data_rate_liste_i,liste_dir,liste_dir_task,liste_tu,price_task_u)

          total_i=task.total_resource_task(ressource,liste_dir,liste_dir_task)

          a_liste=a_list(ressource,liste_dir_task,liste_dir)
          # pour les durées en local
          local_time=vehicle_task[0].local_time(liste_tu,ressource,liste_dir_task)
          all_local=vehicle_task[0].exec_time_all_l(liste_tt,ressource_ve_task,liste_dir_task)
          ressource_ve_task=vehicle_task[0].liste_update_ressource(ressource_ve_task,ressource,liste_dir,liste_dir_task)
          # les durées V2V

          time_up=vehicle_task[0].list_time_to_service(a_liste,liste_tu,data_rate_liste_v,liste_dir,liste_dir_task)
          exec_time=vehicle_serv[0].list_time_exec(a_liste,liste_tu,data_rate_liste_v,liste_dir,liste_dir_task)
          return_time=vehicle_serv[0].liste_return_time(a_liste,liste_tu,data_rate_liste_v,liste_dir,liste_dir_task) # a revoir
          
          mec_liste=vehicle_serv[0].list_time_mec(liste_tu,time_up,exec_time,return_time,liste_dir,liste_dir_task) 

          #le cloud
          #cloud.Pcloud
          check_ressource=vehicle_serv[0].send_to_cloud_msg(vehicle_serv,resource_serv)
          ressource_cloud_init=cloud.get_init_cloud(liste_dir)
          ressource_cloud_used=cloud.ressource_used(check_ressource,ressource,ressource_cloud_init,liste_dir)
          ressource_cloud=cloud.update_ressource(ressource_cloud_used,ressource_cloud,liste_dir)
          #les durées avec le RSU et le cloud V2I
          liste_up_rsu=vehicle_task[0].list_time_to_rsu(a_liste,liste_tu,data_rate_liste_i,ressource,resource_serv,liste_dir_task)
          liste_rsu_cloud_time=rsu.liste_time_rsu_cloud(a_liste,resource_serv,ressource,RSU,liste_tu,liste_dir,liste_dir_task)
          liste_exec_cloud=cloud.liste_exec_time(a_liste,liste_tu,ressource,resource_serv,liste_dir,liste_dir_task)
          liste_cloud_rsu_time=cloud.liste_time_cloud_rsu(a_liste,resource_serv,ressource,RSU,liste_tu,liste_dir,liste_dir_task)
          liste_rsu_return_time=rsu.liste_return_time_rsu(a_liste,resource_serv,ressource,liste_tu,data_rate_liste_i,liste_dir,liste_dir_task)
          time_cloud=cloud.liste_time_cloud(liste_up_rsu,liste_rsu_cloud_time,liste_exec_cloud,liste_cloud_rsu_time,liste_rsu_return_time,check_ressource,liste_dir,liste_dir_task)
            
          #pour le temps maximale de décharge
          time_complete_u=vehicle_task[0].time_complete_u(local_time,mec_liste,time_cloud,liste_dir_task)
          time_all_complete=vehicle_task[0].time_all_complete(time_complete_u,liste_dir_task)


          #reward_task=0    normalement on a reward=rewards[j]
          #reward_service=0    normalement on a reward=rewards[i]

          #recompenses des vehicules de services
          first_term=vehicle_serv[0].first_term(price_task_u,liste_tu,ressource,liste_dir,liste_dir_task)
          second_term=vehicle_serv[0].second_term(a_liste,liste_tu,total_i,ressource,liste_dir,liste_dir_task)
          third_term=vehicle_serv[0].third_term(ressource_cloud_used,liste_dir)
          rewards_serv=vehicle_serv[0].reward(first_term,second_term,third_term,liste_dir)

          # Determiner les rewards des vehicules a taches sous forme de listes globale
          
          p_pay=vehicle_task[0].p_pay(ressource,price_task_u,liste_dir,liste_dir_task)
          reward_task=vehicle_task[0].list_reward_task(all_local,time_all_complete,p_pay,liste_tt,liste_dir_task)
          
          
          '''ddi,ddj,uui,uuj,lli,llj,rri,rrj=0,0,0,0,0,0,0,0

          for j in range(len(vehicle_serv)):
              if vehicle_serv[j].direction=='d':
                  
              
                  for i in range(len(vehicle_task)):
                      if vehicle_task[i].direction=='d':
                          score_d=0
                          all_local_i=all_local[0][ddj]
                          p_pay_i=p_pay[0][ddj]
                          task_time=liste_tt[0][ddj][3]
                          state_task_j=state_task[0][ddj]
                          action_task_j=liste_tu[0][ddj][ddi]
                          if check_ressource==False:
                              time_cloud=ressource_cloud_init
                              time_complete_u=vehicle_task[0].time_complete_u(local_time,mec_liste,time_cloud)
                              time_all_complete_u=vehicle_task[0].time_all_complete(time_complete_u)[0][ddj][ddi]
                              reward_task_i=vehicle_task[0].reward_task_vehicle(time_all,time_all_complete_u,p_pay,task_time)
                          '''
          




        #Pour le véhicules de services
          #states=vehicle_serv[0].state_space(vehicle_serv,env_serv,resource_serv,ressource,liste_dir,liste_dir_task)  
          score_serv =0
          score_task=0
          #print(resource_serv)




          ddi,uui,lli,rri=0,0,0,0
          states=vehicle_serv[0].state_space(vehicle_serv,env_serv,resource_serv,ressource,liste_dir,liste_dir_task)
          actions=price_base
          rewards=rewards_serv



          #liste_dir_next=liste_dir_func(vehicle_serv,n_serv)
          #liste_dir_task_next=liste_dir_task_func(vehicle_task,n_task)

          """ next_task=Task()
          next_liste=next_task.global_task(n_task)
          next_liste_t=next_task.max_time_add_to_task(vehicle_task,next_liste)
          next_liste_tu=next_task.task_to_subtask(next_liste_t,vehicle_serv,liste_dir_next)
          next_ressource=vehicle_task[0].list_resource_required(next_liste_tu,vehicle_task,vehicle_serv,liste_dir_next)
          next_ressource_serv=vehicle_serv[0].liste_update_resource(next_ressource,resource_serv,liste_dir_next,liste_dir_task_next)
          #ressource_required_next="""
          #ressource_service_util=vehicle_serv[0].ressource_utilization(ressource,liste_dir,liste_dir_task)
          next_states=vehicle_serv[0].next_state_space(states,liste_dir)
          next_states_task=vehicle_task[0].next_state_space(state_task,liste_dir_task)
          
          #vehicle_task[0].liste_update_ressource(ressource_ve_task,ressource,liste_dir,liste_dir_task)
          
          big_states=[]
          big_next_states=[]
          big_actions=[]
          big_rewards=[]
          
          for i in range(len(vehicle_serv)):
            dd1,uu1,ll1,rr1=[],[],[],[]
            dd2,uu2,ll2,rr2=[],[],[],[]
            
            
            if vehicle_serv[i].direction=='d':
              m=[]
              #c.append(states[0][ddi])
              #n.append(next_states[0][ddi])
              #k.append(actions[0][ddi])
             
              dd1.append(states[0][ddi])
              m.append(rewards[0][ddi])
              dd2.append(next_states[0][ddi])
              big_actions.append(actions[0][ddi])
              big_rewards.append(m)
              big_states.append(dd1)
              big_next_states.append(dd2)
              ddi+=1

            elif vehicle_serv[i].direction=='u':
                m=[]
              #c.append(states[0][ddi])
              #n.append(next_states[0][ddi])
              #k.append(actions[0][ddi])
                
                uu1.append(states[1][uui])
                m.append(rewards[1][uui])
                uu2.append(next_states[1][uui])
                big_actions.append(actions[1][uui])
                big_rewards.append(m)
                big_states.append(uu1)
                big_next_states.append(uu2)
                uui+=1

            elif vehicle_serv[i].direction=='l':
                  m=[]
                #c.append(states[0][ddi])
                #n.append(next_states[0][ddi])
                #k.append(actions[0][ddi])
                  
                  ll1.append(states[2][lli])
                  m.append(rewards[2][lli])
                  ll2.append(next_states[2][lli])
                  big_actions.append(actions[2][lli])
                  big_rewards.append(m)
                  big_states.append(ll1)
                  big_next_states.append(ll2)
                  lli+=1


            elif vehicle_serv[i].direction=='r':
                  m=[]
                #c.append(states[0][ddi])
                #n.append(next_states[0][ddi])
                #k.append(actions[0][ddi])
                  
                  rr1.append(states[3][rri])
                  m.append(rewards[3][rri])
                  rr2.append(next_states[3][rri])
                  big_actions.append(actions[3][rri])
                  big_rewards.append(m)
                  big_states.append(rr1)
                  big_next_states.append(rr2)
                  rri+=1
          
          xx1=concatenat(big_states)
          yy1=np.array(xx1)
          yy1=np.array(yy1)
        # print(big_states)
          xx2=concatenat(big_next_states)
          #print(big_states)
          yy2=np.array(xx2)
          yy2=np.array(yy2)
          big_actions=np.array(big_actions)
          big_rewards=np.array(big_rewards)


          
  #big_states[0][None,:]
          zz=[yy1[index][:] for index in range(len(vehicle_serv))]
          t=np.concatenate(zz)
          #t=np.concatenate(t)
          yy=[yy2[index][:] for index in range(len(vehicle_serv))]
          t_next=np.concatenate(yy)
          #t_next=np.concatenate(t_next)
          hh=[big_rewards[index][None, :] for index in range(len(vehicle_serv))]
          kk=np.concatenate(hh)
          kk=np.concatenate(kk)


          serv_memory=ReplayBuffer_Serv(BUFFER_CAPACITY,BATCH_SIZE,vehicle_serv,yy1,yy2)
          super_agent = SuperAgent_serv(vehicle_serv,serv_memory,states,price_base,liste_dir)
        # for i in range(len(vehicle_serv)):
          super_agent.replay_buffer.add_record(yy1, yy2, big_actions, t, t_next, kk)              
         
          score_serv += sum(kk)

          env_serv.renew_positions()
          env_serv.renew_neighbor()
          env_task.renew_positions()
          env_task.renew_neighbor()


          
  if super_agent.replay_buffer.check_buffer_size():
              super_agent.train()

  score_servs.append(score_serv)
  score_tasks.append(score_task)

  wandb.log({'Game number': 6, '# Episodes': bb, 
                     "Average reward": round(np.mean(score_servs[:]), 2), \
                      "Time taken": round(time.time() - start_time, 2), 'Max steps': 60})